{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ§ª StreamSage Data Lab: Oracle (Subtitle Engineering)\n",
                "\n",
                "**Goal**: Master the art of preparing unstructured text (movie subtitles) for RAG (Retrieval Augmented Generation).\n",
                "\n",
                "**The Problem**: Raw `.srt` files are messy. They contain HTML, sound effects, and are broken into tiny 2-second lines. If we feed this directly to an LLM, it will get confused.\n",
                "\n",
                "**The Solution**: \n",
                "1. **Clean**: Remove artifacts.\n",
                "2. **Merge**: Combine lines into coherent sentences.\n",
                "3. **Chunk**: Create 5-minute \"Time Windows\" with overlap.\n",
                "\n",
                "**Outcome**: A clean dataset ready for Vector Embedding."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup & Imports\n",
                "!pip install pysrt sentence-transformers pandas\n",
                "\n",
                "import pysrt\n",
                "import re\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sentence_transformers import SentenceTransformer\n",
                "\n",
                "print(\"Libraries installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Get Data\n",
                "We'll download a sample `.srt` file (e.g., *Big Buck Bunny*, an open-source movie) to practice on."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download sample subtitle\n",
                "!wget -O sample.srt https://raw.githubusercontent.com/AGiuliani/Whisper-Subtitles-Generation/main/test/test.srt\n",
                "\n",
                "# Load it\n",
                "subs = pysrt.open('sample.srt')\n",
                "print(f\"Loaded {len(subs)} subtitle lines.\")\n",
                "\n",
                "# Show raw data\n",
                "print(\"\\n--- Raw Data Sample ---\")\n",
                "for i in range(5):\n",
                "    print(f\"[{subs[i].start} -> {subs[i].end}] {subs[i].text}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Cleaning Lab\n",
                "**Task**: Write a function to clean the text.\n",
                "- Remove HTML tags (`<i>`, `<b>`).\n",
                "- Remove sound effects (anything in `[]` or `()`).\n",
                "- Fix multiple spaces."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_text(text):\n",
                "    # 1. Remove HTML tags\n",
                "    text = re.sub(r'<[^>]+>', '', text)\n",
                "    # 2. Remove sound effects [Music], (Laughs)\n",
                "    text = re.sub(r'\\[.*?\\]', '', text)\n",
                "    text = re.sub(r'\\(.*?\\)', '', text)\n",
                "    # 3. Remove music notes\n",
                "    text = re.sub(r'[â™ªâ™«]', '', text)\n",
                "    # 4. Normalize whitespace\n",
                "    text = re.sub(r'\\s+', ' ', text).strip()\n",
                "    return text\n",
                "\n",
                "# Test it\n",
                "dirty_sample = \"<i>(Music playing)</i> Hello <b>World</b>! [Gunshot]\"\n",
                "print(f\"Dirty: {dirty_sample}\")\n",
                "print(f\"Clean: {clean_text(dirty_sample)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Engineering: Sliding Window Chunking\n",
                "\n",
                "**Concept**: We can't search line-by-line (too short). We can't search the whole movie (too long).\n",
                "We need **Windows**.\n",
                "\n",
                "- **Window Size**: 300 seconds (5 mins)\n",
                "- **Overlap**: 30 seconds\n",
                "\n",
                "Why overlap? Imagine a sentence starts at 4:59 and ends at 5:01. Without overlap, we'd cut it in half!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_chunks(subs, window_size=300, overlap=30):\n",
                "    chunks = []\n",
                "    \n",
                "    # Convert all to seconds\n",
                "    end_time = subs[-1].end.ordinal / 1000\n",
                "    \n",
                "    current_start = 0\n",
                "    \n",
                "    while current_start < end_time:\n",
                "        current_end = current_start + window_size\n",
                "        \n",
                "        # Collect text in this window\n",
                "        window_text = []\n",
                "        for sub in subs:\n",
                "            sub_start = sub.start.ordinal / 1000\n",
                "            sub_end = sub.end.ordinal / 1000\n",
                "            \n",
                "            # Check if sub is inside window\n",
                "            if sub_start >= current_start and sub_end <= current_end:\n",
                "                cleaned = clean_text(sub.text)\n",
                "                if cleaned:\n",
                "                    window_text.append(cleaned)\n",
                "        \n",
                "        # Save chunk\n",
                "        if window_text:\n",
                "            chunks.append({\n",
                "                'start': current_start,\n",
                "                'end': current_end,\n",
                "                'text': ' '.join(window_text),\n",
                "                'char_count': len(' '.join(window_text))\n",
                "            })\n",
                "            \n",
                "        # Slide window\n",
                "        current_start += (window_size - overlap)\n",
                "        \n",
                "    return pd.DataFrame(chunks)\n",
                "\n",
                "# Run it (using smaller window for this short demo file)\n",
                "df_chunks = create_chunks(subs, window_size=30, overlap=5)\n",
                "df_chunks.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualization\n",
                "Let's see the distribution of our chunks. Are they too big? Too small?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 5))\n",
                "plt.hist(df_chunks['char_count'], bins=20, color='purple', alpha=0.7)\n",
                "plt.title('Distribution of Chunk Sizes (Characters)')\n",
                "plt.xlabel('Characters')\n",
                "plt.ylabel('Count')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Vector Embeddings (Preview)\n",
                "Now that we have clean chunks, let's turn them into numbers (vectors) using a pre-trained model.\n",
                "This is what `ChromaDB` does under the hood."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "\n",
                "# Embed the first chunk\n",
                "sample_text = df_chunks.iloc[0]['text']\n",
                "vector = model.encode(sample_text)\n",
                "\n",
                "print(f\"Text: {sample_text[:50]}...\")\n",
                "print(f\"Vector Shape: {vector.shape}\")\n",
                "print(f\"First 10 dimensions: {vector[:10]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## âœ… Next Steps\n",
                "1. Download this notebook.\n",
                "2. Upload to Google Colab.\n",
                "3. Try it with **YOUR** favorite movie's `.srt` file.\n",
                "4. Adjust `window_size` and see how it changes the chunks."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}