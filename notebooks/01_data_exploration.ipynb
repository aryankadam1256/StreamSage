{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä StreamSage Notebook 1: Data Exploration\n",
                "\n",
                "**Goal**: Download and explore all datasets for the Movie Discovery Assistant.\n",
                "\n",
                "**Datasets**:\n",
                "1. MovieLens 25M - User ratings and preferences\n",
                "2. TMDb 5000 - Movie metadata (plots, cast, keywords)\n",
                "3. IMDb Reviews - Sentiment analysis data\n",
                "\n",
                "**Outcome**: Understand data structure, quality, and merge strategy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required libraries\n",
                "!pip install pandas numpy matplotlib seaborn kaggle\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datetime import datetime\n",
                "import json\n",
                "\n",
                "# Set display options\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.max_rows', 100)\n",
                "\n",
                "print(\"‚úÖ Libraries loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Dataset 1: MovieLens 25M\n",
                "\n",
                "**What it contains**: 25 million ratings from 162,000 users on 62,000 movies.\n",
                "\n",
                "**Why we need it**: User preference patterns for personalized recommendations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download MovieLens 25M\n",
                "!wget https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
                "!unzip -q ml-25m.zip\n",
                "\n",
                "print(\"‚úÖ MovieLens 25M downloaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load MovieLens data\n",
                "ml_ratings = pd.read_csv('ml-25m/ratings.csv')\n",
                "ml_movies = pd.read_csv('ml-25m/movies.csv')\n",
                "ml_tags = pd.read_csv('ml-25m/tags.csv')\n",
                "\n",
                "print(f\"Ratings shape: {ml_ratings.shape}\")\n",
                "print(f\"Movies shape: {ml_movies.shape}\")\n",
                "print(f\"Tags shape: {ml_tags.shape}\")\n",
                "\n",
                "print(\"\\n--- Ratings Sample ---\")\n",
                "display(ml_ratings.head())\n",
                "\n",
                "print(\"\\n--- Movies Sample ---\")\n",
                "display(ml_movies.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# MovieLens Statistics\n",
                "print(\"üìä MovieLens Statistics\")\n",
                "print(f\"Total ratings: {len(ml_ratings):,}\")\n",
                "print(f\"Unique users: {ml_ratings['userId'].nunique():,}\")\n",
                "print(f\"Unique movies: {ml_ratings['movieId'].nunique():,}\")\n",
                "print(f\"Average rating: {ml_ratings['rating'].mean():.2f}\")\n",
                "print(f\"Rating range: {ml_ratings['rating'].min()} - {ml_ratings['rating'].max()}\")\n",
                "\n",
                "# Visualize rating distribution\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.subplot(1, 2, 1)\n",
                "ml_ratings['rating'].hist(bins=10, color='skyblue', edgecolor='black')\n",
                "plt.title('Rating Distribution')\n",
                "plt.xlabel('Rating')\n",
                "plt.ylabel('Count')\n",
                "\n",
                "# Ratings per movie\n",
                "plt.subplot(1, 2, 2)\n",
                "ratings_per_movie = ml_ratings.groupby('movieId').size()\n",
                "ratings_per_movie.hist(bins=50, color='coral', edgecolor='black')\n",
                "plt.title('Ratings per Movie')\n",
                "plt.xlabel('Number of Ratings')\n",
                "plt.ylabel('Number of Movies')\n",
                "plt.yscale('log')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Dataset 2: TMDb 5000 Movies\n",
                "\n",
                "**What it contains**: Rich metadata for 5,000 movies (plots, cast, keywords).\n",
                "\n",
                "**Why we need it**: Content-based recommendations using plot similarity."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download TMDb dataset from Kaggle\n",
                "# Note: You need to upload your kaggle.json API key first\n",
                "# Go to: https://www.kaggle.com/settings/account ‚Üí Create New API Token\n",
                "# Upload kaggle.json to Colab\n",
                "\n",
                "from google.colab import files\n",
                "print(\"üì§ Please upload your kaggle.json file:\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Setup Kaggle\n",
                "!mkdir -p ~/.kaggle\n",
                "!cp kaggle.json ~/.kaggle/\n",
                "!chmod 600 ~/.kaggle/kaggle.json\n",
                "\n",
                "# Download dataset\n",
                "!kaggle datasets download -d tmdb/tmdb-movie-metadata\n",
                "!unzip -q tmdb-movie-metadata.zip\n",
                "\n",
                "print(\"‚úÖ TMDb dataset downloaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load TMDb data\n",
                "tmdb_movies = pd.read_csv('tmdb_5000_movies.csv')\n",
                "tmdb_credits = pd.read_csv('tmdb_5000_credits.csv')\n",
                "\n",
                "print(f\"TMDb Movies shape: {tmdb_movies.shape}\")\n",
                "print(f\"TMDb Credits shape: {tmdb_credits.shape}\")\n",
                "\n",
                "print(\"\\n--- TMDb Movies Sample ---\")\n",
                "display(tmdb_movies.head())\n",
                "\n",
                "print(\"\\n--- Column Names ---\")\n",
                "print(tmdb_movies.columns.tolist())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TMDb Statistics\n",
                "print(\"üìä TMDb Statistics\")\n",
                "print(f\"Total movies: {len(tmdb_movies):,}\")\n",
                "print(f\"Movies with overview: {tmdb_movies['overview'].notna().sum():,}\")\n",
                "print(f\"Missing overviews: {tmdb_movies['overview'].isna().sum()}\")\n",
                "print(f\"Average overview length: {tmdb_movies['overview'].str.len().mean():.0f} characters\")\n",
                "\n",
                "# Check a sample overview\n",
                "print(\"\\n--- Sample Movie Overview ---\")\n",
                "sample = tmdb_movies.iloc[0]\n",
                "print(f\"Title: {sample['title']}\")\n",
                "print(f\"Overview: {sample['overview']}\")\n",
                "print(f\"Genres: {sample['genres']}\")\n",
                "print(f\"Keywords: {sample['keywords']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Parse JSON columns (genres, keywords)\n",
                "def parse_json_column(df, column):\n",
                "    \"\"\"Parse JSON string column and extract names\"\"\"\n",
                "    def extract_names(x):\n",
                "        if pd.isna(x):\n",
                "            return []\n",
                "        try:\n",
                "            data = json.loads(x)\n",
                "            return [item['name'] for item in data]\n",
                "        except:\n",
                "            return []\n",
                "    \n",
                "    return df[column].apply(extract_names)\n",
                "\n",
                "# Parse genres and keywords\n",
                "tmdb_movies['genres_list'] = parse_json_column(tmdb_movies, 'genres')\n",
                "tmdb_movies['keywords_list'] = parse_json_column(tmdb_movies, 'keywords')\n",
                "\n",
                "print(\"‚úÖ JSON columns parsed!\")\n",
                "print(\"\\n--- Sample Parsed Data ---\")\n",
                "print(f\"Title: {tmdb_movies.iloc[0]['title']}\")\n",
                "print(f\"Genres: {tmdb_movies.iloc[0]['genres_list']}\")\n",
                "print(f\"Keywords: {tmdb_movies.iloc[0]['keywords_list'][:5]}...\")  # First 5 keywords"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Dataset 3: IMDb Reviews\n",
                "\n",
                "**What it contains**: 50,000 movie reviews with sentiment labels.\n",
                "\n",
                "**Why we need it**: Train sentiment analyzer for review insights."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download IMDb reviews\n",
                "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
                "!tar -xzf aclImdb_v1.tar.gz\n",
                "\n",
                "print(\"‚úÖ IMDb reviews downloaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load IMDb reviews (sample)\n",
                "import os\n",
                "\n",
                "def load_reviews(directory, label):\n",
                "    \"\"\"Load reviews from directory\"\"\"\n",
                "    reviews = []\n",
                "    for filename in os.listdir(directory)[:100]:  # Sample 100 reviews\n",
                "        if filename.endswith('.txt'):\n",
                "            with open(os.path.join(directory, filename), 'r', encoding='utf-8') as f:\n",
                "                reviews.append({'text': f.read(), 'sentiment': label})\n",
                "    return reviews\n",
                "\n",
                "# Load positive and negative reviews\n",
                "pos_reviews = load_reviews('aclImdb/train/pos', 'positive')\n",
                "neg_reviews = load_reviews('aclImdb/train/neg', 'negative')\n",
                "\n",
                "# Create DataFrame\n",
                "imdb_reviews = pd.DataFrame(pos_reviews + neg_reviews)\n",
                "\n",
                "print(f\"IMDb Reviews shape: {imdb_reviews.shape}\")\n",
                "print(f\"Positive: {(imdb_reviews['sentiment'] == 'positive').sum()}\")\n",
                "print(f\"Negative: {(imdb_reviews['sentiment'] == 'negative').sum()}\")\n",
                "\n",
                "print(\"\\n--- Sample Review ---\")\n",
                "print(imdb_reviews.iloc[0]['text'][:300] + \"...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîó Merge Strategy Analysis\n",
                "\n",
                "**Challenge**: MovieLens and TMDb use different IDs.\n",
                "\n",
                "**Solution**: Match by title + year."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract year from MovieLens title\n",
                "ml_movies['year'] = ml_movies['title'].str.extract(r'\\((\\d{4})\\)')[0]\n",
                "ml_movies['clean_title'] = ml_movies['title'].str.replace(r'\\s*\\(\\d{4}\\)', '', regex=True)\n",
                "\n",
                "# Extract year from TMDb\n",
                "tmdb_movies['year'] = pd.to_datetime(tmdb_movies['release_date'], errors='coerce').dt.year.astype('Int64')\n",
                "\n",
                "print(\"‚úÖ Years extracted!\")\n",
                "print(\"\\n--- MovieLens Sample ---\")\n",
                "display(ml_movies[['movieId', 'title', 'clean_title', 'year']].head())\n",
                "\n",
                "print(\"\\n--- TMDb Sample ---\")\n",
                "display(tmdb_movies[['id', 'title', 'year']].head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test merge on exact title + year match\n",
                "merged_test = ml_movies.merge(\n",
                "    tmdb_movies,\n",
                "    left_on=['clean_title', 'year'],\n",
                "    right_on=['title', 'year'],\n",
                "    how='inner',\n",
                "    suffixes=('_ml', '_tmdb')\n",
                ")\n",
                "\n",
                "print(f\"üìä Merge Results (Exact Match)\")\n",
                "print(f\"MovieLens movies: {len(ml_movies):,}\")\n",
                "print(f\"TMDb movies: {len(tmdb_movies):,}\")\n",
                "print(f\"Matched movies: {len(merged_test):,}\")\n",
                "print(f\"Match rate: {len(merged_test) / len(tmdb_movies) * 100:.1f}%\")\n",
                "\n",
                "print(\"\\n--- Sample Merged Data ---\")\n",
                "display(merged_test[['movieId', 'title_ml', 'title_tmdb', 'year', 'overview']].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìã Summary & Next Steps\n",
                "\n",
                "### What We Learned:\n",
                "1. ‚úÖ MovieLens has 25M ratings on 62K movies\n",
                "2. ‚úÖ TMDb has rich metadata for 5K movies\n",
                "3. ‚úÖ We can match ~3-4K movies by title + year\n",
                "4. ‚úÖ IMDb reviews are ready for sentiment training\n",
                "\n",
                "### Next Notebook: Data Cleaning\n",
                "- Remove low-quality data\n",
                "- Handle missing values\n",
                "- Standardize formats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save exploration results\n",
                "print(\"üíæ Saving exploration results...\")\n",
                "\n",
                "# Save basic stats\n",
                "stats = {\n",
                "    'movielens_ratings': len(ml_ratings),\n",
                "    'movielens_movies': len(ml_movies),\n",
                "    'tmdb_movies': len(tmdb_movies),\n",
                "    'matched_movies': len(merged_test),\n",
                "    'imdb_reviews': len(imdb_reviews)\n",
                "}\n",
                "\n",
                "with open('exploration_stats.json', 'w') as f:\n",
                "    json.dump(stats, f, indent=2)\n",
                "\n",
                "print(\"‚úÖ Stats saved to exploration_stats.json\")\n",
                "print(\"\\nüéâ Exploration complete! Ready for Notebook 2: Data Cleaning\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}